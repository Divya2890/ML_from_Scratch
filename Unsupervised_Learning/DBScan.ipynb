{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMsPossFDfDf4VzDy9vO4cM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Implementation of Density Based Spatial Clustering of Applications with Noise"],"metadata":{"id":"8WkLjCRjsr43"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from sklearn import datasets\n","import matplotlib.pyplot as plt"],"metadata":{"id":"xASQU2zAs9QI","executionInfo":{"status":"ok","timestamp":1724961254859,"user_tz":240,"elapsed":4965,"user":{"displayName":"Divya Sree Pulipati","userId":"16558291737148482724"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"MkpNDPcesgju","executionInfo":{"status":"ok","timestamp":1724961321694,"user_tz":240,"elapsed":143,"user":{"displayName":"Divya Sree Pulipati","userId":"16558291737148482724"}}},"outputs":[],"source":["class DB_Scan():\n","  def __init__(self,radius= 0.5, n_minpts=5):\n","    self.radius = radius\n","    self.n_minpts = n_minpts\n","\n","  def euclidean_distance(self,x1,x2):\n","    return np.linalg.norm(x1-x2)\n","\n","  def all_distances(self,x):\n","    # find the distance between all the points in the sample through an nxn matrix\n","    n_samples = x.shape[0]\n","    distance = np.zeros((n_samples, n_samples))\n","    for idx, each_x in enumerate(x):\n","      for idy, other_x in enumerate(x):\n","          distance[idx, idy] = self.euclidean_distance(each_x, other_x)\n","    return distance\n","\n","  def get_neighbour(self,distance, idx):\n","    return np.argwhere(distance[idx] <= self.radius).flatten()\n","\n","  def grow_cluster(self,idx, neighbours):\n","    cluster = [idx]\n","    for each_idx in neighbours[idx]:\n","      if each_idx not in self.visited_sample:\n","        self.visited_sample.append(each_idx)\n","        # find if it is a core point or not\n","        if len(neighbours[each_idx])>= self.n_minpts:\n","          expanded_cluster = self.grow_cluster(each_idx,neighbours)\n","          cluster = cluster + expanded_cluster\n","        else:\n","          cluster.append(each_idx)\n","\n","\n","    return cluster\n","\n","  def get_cluster_labels(self,cluster,x):\n","    labels = np.full(x.shape[0],-1) # labels that are not present with in self.cluster are by default assigned as a noise label\n","    for idx,each_cluster in enumerate(cluster):\n","      for id in each_cluster:\n","        labels[id] = idx\n","    return labels\n","\n","\n","\n","\n","  def predict(self,x):\n","    self.n_cluster  = 0\n","    self.clusters  = [] # the shape of it depends on the no of clusters and it stores the idx of the rows belonging to that cluster\n","    self.visited_sample  = [] # stores the idx of all the data samples that has been visited\n","    self.labels = [] # cluster labels of each sample of data\n","\n","    # First the distance between all the points\n","    dist_all_points = self.all_distances(x)\n","\n","    # get the neighbors and if len(neighbours> minpts, assign them as core)\n","\n","    nb_array = [self.get_neighbour(dist_all_points,idx) for idx,each_x in enumerate(x)]\n","\n","    for idx,each_x in enumerate(x):\n","      if idx not in self.visited_sample:\n","        # check it it can be a core point\n","        if(len(nb_array[idx])>= self.n_minpts):\n","          self.visited_sample.append(idx)\n","          # grow the cluster\n","          new_cluster = self.grow_cluster(idx,nb_array)\n","          self.clusters.append(new_cluster)\n","\n","\n","    predictions = self.get_cluster_labels(self.clusters,x)\n","    return predictions\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["iris = datasets.load_iris()\n","x,y = iris.data,iris.target\n","model = DB_Scan()\n","predictions = model.predict(x)\n","print(\"accuracy\",accuracy_score(predictions,y))\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"raIhCYGcsmji","executionInfo":{"status":"ok","timestamp":1724961330811,"user_tz":240,"elapsed":409,"user":{"displayName":"Divya Sree Pulipati","userId":"16558291737148482724"}},"outputId":"9263a58c-5868-4a46-aa86-9324144a025c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy 0.62\n"]}]},{"cell_type":"code","source":["from sklearn.cluster import DBSCAN\n","\n","\n","sk_model = DBSCAN(eps =0.5,min_samples=5)\n","sk_predictions = sk_model.fit_predict(x)\n","print(\"accuracy\",accuracy_score(sk_predictions,y))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tM9ZUHVMsqQD","executionInfo":{"status":"ok","timestamp":1724961373534,"user_tz":240,"elapsed":143,"user":{"displayName":"Divya Sree Pulipati","userId":"16558291737148482724"}},"outputId":"dc45d38e-4867-43b9-bacb-3dd682ad93ef"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy 0.62\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Q5pArBEqtAem"},"execution_count":null,"outputs":[]}]}